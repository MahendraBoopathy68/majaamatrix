{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "KNN_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdLP6qa3gdpn"
      },
      "source": [
        "# K-Nearest Neighbors for Regression\n",
        "\n",
        "Linear regression is not the only machine learning model that Ashenfelter could have fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzuSByJrEC7N"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "bordeaux_df = pd.read_csv(\"https://dlsun.github.io/pods/data/bordeaux.csv\",\n",
        "                          index_col=\"year\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "SnjNX4c3EWE9",
        "outputId": "d0325322-4cf9-4477-dc7a-76f53494fa16"
      },
      "source": [
        "bordeaux_df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>summer</th>\n",
              "      <th>har</th>\n",
              "      <th>sep</th>\n",
              "      <th>win</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>37.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>160</td>\n",
              "      <td>14.3</td>\n",
              "      <td>600</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>63.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>80</td>\n",
              "      <td>17.3</td>\n",
              "      <td>690</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>45.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>130</td>\n",
              "      <td>16.8</td>\n",
              "      <td>502</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1957</th>\n",
              "      <td>22.0</td>\n",
              "      <td>16.1</td>\n",
              "      <td>110</td>\n",
              "      <td>16.2</td>\n",
              "      <td>420</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>18.0</td>\n",
              "      <td>16.4</td>\n",
              "      <td>187</td>\n",
              "      <td>19.1</td>\n",
              "      <td>582</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  summer  har   sep  win  age\n",
              "year                                    \n",
              "1952   37.0    17.1  160  14.3  600   40\n",
              "1953   63.0    16.7   80  17.3  690   39\n",
              "1955   45.0    17.1  130  16.8  502   37\n",
              "1957   22.0    16.1  110  16.2  420   35\n",
              "1958   18.0    16.4  187  19.1  582   34"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "nszYpFRka2nB",
        "outputId": "241ed51c-8808-4889-ae1c-ec00c057dc93"
      },
      "source": [
        "bordeaux_df.tail(15)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>summer</th>\n",
              "      <th>har</th>\n",
              "      <th>sep</th>\n",
              "      <th>win</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1977</th>\n",
              "      <td>11.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>87</td>\n",
              "      <td>16.8</td>\n",
              "      <td>821</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>27.0</td>\n",
              "      <td>15.8</td>\n",
              "      <td>51</td>\n",
              "      <td>17.4</td>\n",
              "      <td>763</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>21.0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>122</td>\n",
              "      <td>17.3</td>\n",
              "      <td>717</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>74</td>\n",
              "      <td>18.4</td>\n",
              "      <td>578</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>111</td>\n",
              "      <td>18.0</td>\n",
              "      <td>535</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.4</td>\n",
              "      <td>162</td>\n",
              "      <td>18.5</td>\n",
              "      <td>712</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1983</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.4</td>\n",
              "      <td>119</td>\n",
              "      <td>17.9</td>\n",
              "      <td>845</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1984</th>\n",
              "      <td>NaN</td>\n",
              "      <td>16.5</td>\n",
              "      <td>119</td>\n",
              "      <td>16.0</td>\n",
              "      <td>591</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>NaN</td>\n",
              "      <td>16.8</td>\n",
              "      <td>38</td>\n",
              "      <td>18.9</td>\n",
              "      <td>744</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1986</th>\n",
              "      <td>NaN</td>\n",
              "      <td>16.3</td>\n",
              "      <td>171</td>\n",
              "      <td>17.5</td>\n",
              "      <td>563</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.0</td>\n",
              "      <td>115</td>\n",
              "      <td>18.9</td>\n",
              "      <td>452</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.1</td>\n",
              "      <td>59</td>\n",
              "      <td>16.8</td>\n",
              "      <td>808</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1989</th>\n",
              "      <td>NaN</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>18.4</td>\n",
              "      <td>443</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>NaN</td>\n",
              "      <td>18.7</td>\n",
              "      <td>80</td>\n",
              "      <td>19.3</td>\n",
              "      <td>468</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>NaN</td>\n",
              "      <td>17.7</td>\n",
              "      <td>183</td>\n",
              "      <td>20.4</td>\n",
              "      <td>570</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  summer  har   sep  win  age\n",
              "year                                    \n",
              "1977   11.0    15.6   87  16.8  821   15\n",
              "1978   27.0    15.8   51  17.4  763   14\n",
              "1979   21.0    16.2  122  17.3  717   13\n",
              "1980   14.0    16.0   74  18.4  578   12\n",
              "1981    NaN    17.0  111  18.0  535   11\n",
              "1982    NaN    17.4  162  18.5  712   10\n",
              "1983    NaN    17.4  119  17.9  845    9\n",
              "1984    NaN    16.5  119  16.0  591    8\n",
              "1985    NaN    16.8   38  18.9  744    7\n",
              "1986    NaN    16.3  171  17.5  563    6\n",
              "1987    NaN    17.0  115  18.9  452    5\n",
              "1988    NaN    17.1   59  16.8  808    4\n",
              "1989    NaN    18.6   82  18.4  443    3\n",
              "1990    NaN    18.7   80  19.3  468    2\n",
              "1991    NaN    17.7  183  20.4  570    1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "kku0zPJeEJKN",
        "outputId": "164843e8-fdac-42cb-859e-85ab4fd90f4c"
      },
      "source": [
        "bordeaux_df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>summer</th>\n",
              "      <th>har</th>\n",
              "      <th>sep</th>\n",
              "      <th>win</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>27.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>38.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>28.814815</td>\n",
              "      <td>16.715789</td>\n",
              "      <td>135.500000</td>\n",
              "      <td>17.392105</td>\n",
              "      <td>609.421053</td>\n",
              "      <td>19.631579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>20.956066</td>\n",
              "      <td>0.781726</td>\n",
              "      <td>67.429944</td>\n",
              "      <td>1.439854</td>\n",
              "      <td>131.370866</td>\n",
              "      <td>11.336192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>376.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>14.000000</td>\n",
              "      <td>16.225000</td>\n",
              "      <td>86.250000</td>\n",
              "      <td>16.425000</td>\n",
              "      <td>535.250000</td>\n",
              "      <td>10.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>22.000000</td>\n",
              "      <td>16.700000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>17.300000</td>\n",
              "      <td>586.500000</td>\n",
              "      <td>19.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>17.100000</td>\n",
              "      <td>171.000000</td>\n",
              "      <td>18.400000</td>\n",
              "      <td>713.500000</td>\n",
              "      <td>28.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>18.700000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>20.400000</td>\n",
              "      <td>845.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            price     summer         har        sep         win        age\n",
              "count   27.000000  38.000000   38.000000  38.000000   38.000000  38.000000\n",
              "mean    28.814815  16.715789  135.500000  17.392105  609.421053  19.631579\n",
              "std     20.956066   0.781726   67.429944   1.439854  131.370866  11.336192\n",
              "min     10.000000  15.000000   38.000000  14.300000  376.000000   1.000000\n",
              "25%     14.000000  16.225000   86.250000  16.425000  535.250000  10.250000\n",
              "50%     22.000000  16.700000  119.000000  17.300000  586.500000  19.500000\n",
              "75%     35.000000  17.100000  171.000000  18.400000  713.500000  28.750000\n",
              "max    100.000000  18.700000  292.000000  20.400000  845.000000  40.000000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-UG-AQSbM8s",
        "outputId": "474f1a8a-e52f-429a-99b0-dc9c00e9b1a2"
      },
      "source": [
        "bordeaux_df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwOMv33Jgdpp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1cc9280a-33ae-432e-c5ca-6bb0e28e9ca8"
      },
      "source": [
        "# Split the data into training and test sets.\n",
        "bordeaux_train = bordeaux_df.loc[:1980].copy()\n",
        "bordeaux_test = bordeaux_df.loc[1981:].copy()\n",
        "\n",
        "# Log transform the target.\n",
        "bordeaux_train[\"log(price)\"] = np.log(bordeaux_train[\"price\"])\n",
        "bordeaux_train.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>summer</th>\n",
              "      <th>har</th>\n",
              "      <th>sep</th>\n",
              "      <th>win</th>\n",
              "      <th>age</th>\n",
              "      <th>log(price)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>37.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>160</td>\n",
              "      <td>14.3</td>\n",
              "      <td>600</td>\n",
              "      <td>40</td>\n",
              "      <td>3.610918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>63.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>80</td>\n",
              "      <td>17.3</td>\n",
              "      <td>690</td>\n",
              "      <td>39</td>\n",
              "      <td>4.143135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>45.0</td>\n",
              "      <td>17.1</td>\n",
              "      <td>130</td>\n",
              "      <td>16.8</td>\n",
              "      <td>502</td>\n",
              "      <td>37</td>\n",
              "      <td>3.806662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1957</th>\n",
              "      <td>22.0</td>\n",
              "      <td>16.1</td>\n",
              "      <td>110</td>\n",
              "      <td>16.2</td>\n",
              "      <td>420</td>\n",
              "      <td>35</td>\n",
              "      <td>3.091042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>18.0</td>\n",
              "      <td>16.4</td>\n",
              "      <td>187</td>\n",
              "      <td>19.1</td>\n",
              "      <td>582</td>\n",
              "      <td>34</td>\n",
              "      <td>2.890372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  summer  har   sep  win  age  log(price)\n",
              "year                                                \n",
              "1952   37.0    17.1  160  14.3  600   40    3.610918\n",
              "1953   63.0    16.7   80  17.3  690   39    4.143135\n",
              "1955   45.0    17.1  130  16.8  502   37    3.806662\n",
              "1957   22.0    16.1  110  16.2  420   35    3.091042\n",
              "1958   18.0    16.4  187  19.1  582   34    2.890372"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obIRRRtTgdpu"
      },
      "source": [
        "Let's focus on just two features for now: winter rainfall (**win**) and average summer temperature (**summer**). Let's plot the training data, using a color gradient to represent the target (**log(price)**). Notice how we can customize the color gradient using the `cmap=` argument. A list of the available colormaps can be found [here](https://matplotlib.org/examples/color/colormaps_reference.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LpV-ttBgdpw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "5ffc280d-85c0-46f8-f276-139880cc6158"
      },
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "bordeaux_train.plot.scatter(x=\"win\", y=\"summer\", c=\"log(price)\", \n",
        "                            cmap=cm.YlOrRd)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9419ed4290>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr_2sHvrgdpz"
      },
      "source": [
        "Notice how wines that are close on this scatterplot are of similar quality. This insight is the basis of the $k$-nearest neighbors algorithm for predicting wine quality. Suppose that we want to predict the quality of the 1986 vintage, represented by a blue star in the plot below. \n",
        "\n",
        "![](https://github.com/dlsun/pods/blob/master/05-Regression-Models/regression_neighbors.png?raw=1)\n",
        "\n",
        "The $k=5$ points that are closest to this point in feature space are indicated by dotted lines. We can average the qualities of thse wines to obtain our prediction. All 5 of these points have a quality less than 3.0, so the 1986 vintage is also predicted to be of low quality.\n",
        "\n",
        "The $k$-nearest neighbors regression algorithm can be summarized as follows:\n",
        "\n",
        "1. Determine the $k$ closest points in the training data to the new point that you want to predict for, based on some distance metric on the features.\n",
        "2. The predicted label of the new point is the mean (or median) of the labels of the $k$ closest points.\n",
        "\n",
        "Let's implement this in code. First, we extract the training data and scale the features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LMYQFf7gdp0"
      },
      "source": [
        "X_train = bordeaux_train[[\"win\", \"summer\"]]\n",
        "y_train = bordeaux_train[\"log(price)\"]\n",
        "\n",
        "# Standardize the features.\n",
        "X_train_mean = X_train.mean()\n",
        "X_train_sd = X_train.std()\n",
        "X_train_st = (X_train - X_train_mean) / X_train_sd"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "8SPfQBeJF37z",
        "outputId": "84438f6f-6b60-47ea-c683-69d5fe10bedb"
      },
      "source": [
        "X_train_st"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>win</th>\n",
              "      <th>summer</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1952</th>\n",
              "      <td>-0.065156</td>\n",
              "      <td>0.965533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1953</th>\n",
              "      <td>0.632329</td>\n",
              "      <td>0.352135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1955</th>\n",
              "      <td>-0.824640</td>\n",
              "      <td>0.965533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1957</th>\n",
              "      <td>-1.460127</td>\n",
              "      <td>-0.567960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>-0.204653</td>\n",
              "      <td>-0.107912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>-0.956387</td>\n",
              "      <td>1.578930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>1.198068</td>\n",
              "      <td>-0.107912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>1.717307</td>\n",
              "      <td>1.272231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>0.686578</td>\n",
              "      <td>-0.261262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>-0.003157</td>\n",
              "      <td>-1.181358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>-1.599624</td>\n",
              "      <td>1.272231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>-0.049656</td>\n",
              "      <td>-1.641406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1966</th>\n",
              "      <td>1.632058</td>\n",
              "      <td>0.045437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>0.818325</td>\n",
              "      <td>-0.414611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>0.012342</td>\n",
              "      <td>-0.414611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1969</th>\n",
              "      <td>-0.258902</td>\n",
              "      <td>0.045437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1970</th>\n",
              "      <td>0.105340</td>\n",
              "      <td>0.352135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1971</th>\n",
              "      <td>-0.444898</td>\n",
              "      <td>0.505485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1972</th>\n",
              "      <td>-0.561146</td>\n",
              "      <td>-2.254803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1973</th>\n",
              "      <td>-1.801120</td>\n",
              "      <td>0.965533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>-0.266652</td>\n",
              "      <td>-0.261262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1975</th>\n",
              "      <td>-0.282152</td>\n",
              "      <td>0.658834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1976</th>\n",
              "      <td>-1.475627</td>\n",
              "      <td>1.732279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1977</th>\n",
              "      <td>1.647558</td>\n",
              "      <td>-1.334707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>1.198068</td>\n",
              "      <td>-1.028008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1979</th>\n",
              "      <td>0.841575</td>\n",
              "      <td>-0.414611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>-0.235652</td>\n",
              "      <td>-0.721310</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           win    summer\n",
              "year                    \n",
              "1952 -0.065156  0.965533\n",
              "1953  0.632329  0.352135\n",
              "1955 -0.824640  0.965533\n",
              "1957 -1.460127 -0.567960\n",
              "1958 -0.204653 -0.107912\n",
              "1959 -0.956387  1.578930\n",
              "1960  1.198068 -0.107912\n",
              "1961  1.717307  1.272231\n",
              "1962  0.686578 -0.261262\n",
              "1963 -0.003157 -1.181358\n",
              "1964 -1.599624  1.272231\n",
              "1965 -0.049656 -1.641406\n",
              "1966  1.632058  0.045437\n",
              "1967  0.818325 -0.414611\n",
              "1968  0.012342 -0.414611\n",
              "1969 -0.258902  0.045437\n",
              "1970  0.105340  0.352135\n",
              "1971 -0.444898  0.505485\n",
              "1972 -0.561146 -2.254803\n",
              "1973 -1.801120  0.965533\n",
              "1974 -0.266652 -0.261262\n",
              "1975 -0.282152  0.658834\n",
              "1976 -1.475627  1.732279\n",
              "1977  1.647558 -1.334707\n",
              "1978  1.198068 -1.028008\n",
              "1979  0.841575 -0.414611\n",
              "1980 -0.235652 -0.721310"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp1jBJqNgdp4"
      },
      "source": [
        "Now, we get the features for the new observation (i.e., the 1986 vintage), standardizing it in the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt0eaZ3Cgdp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25758bd6-cf0e-475c-cee9-1c55770a46b7"
      },
      "source": [
        "x_new = bordeaux_test.loc[1986, [\"win\", \"summer\"]]\n",
        "\n",
        "x_new_st = (x_new - X_train_mean) / X_train_sd\n",
        "x_new_st"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "win      -0.351900\n",
              "summer   -0.261262\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liYFVefbF1ah",
        "outputId": "8edb386f-c468-47cf-dee8-fe60e35aa996"
      },
      "source": [
        "x_new_st"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "win      -0.351900\n",
              "summer   -0.261262\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRheuLl-gdp-"
      },
      "source": [
        "Now we calculate the (Euclidean) distances between the 1986 vintage and the vintages in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJK7pzwmgdp_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cce32e8a-bfdc-42a4-f236-dfc240b29668"
      },
      "source": [
        "dists = np.sqrt(((X_train_st - x_new_st) ** 2).sum(axis=1))\n",
        "dists"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "year\n",
              "1952    1.259860\n",
              "1953    1.159726\n",
              "1955    1.314727\n",
              "1957    1.149883\n",
              "1958    0.212597\n",
              "1959    1.936933\n",
              "1960    1.557535\n",
              "1961    2.575503\n",
              "1962    1.038478\n",
              "1963    0.983970\n",
              "1964    1.976971\n",
              "1965    1.412851\n",
              "1966    2.007525\n",
              "1967    1.180230\n",
              "1968    0.395207\n",
              "1969    0.320488\n",
              "1970    0.765065\n",
              "1971    0.772366\n",
              "1972    2.004492\n",
              "1973    1.898753\n",
              "1974    0.085248\n",
              "1975    0.922736\n",
              "1976    2.288442\n",
              "1977    2.269387\n",
              "1978    1.729248\n",
              "1979    1.203287\n",
              "1980    0.474508\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOn2bnnZgdqC"
      },
      "source": [
        "Now, we sort the distances. The first 5 of these are the nearest neighbors. To get the year of these nearest neighbors, we get the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHCsio0NgdqE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0c0665-89f8-44f4-a800-b67bd2df73df"
      },
      "source": [
        "i_nearest = dists.sort_values().index[:5]\n",
        "i_nearest"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([1974, 1958, 1969, 1968, 1980], dtype='int64', name='year')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvLMrn-hgdqG"
      },
      "source": [
        "We can look up these years in the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2GRYEEsgdqH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6c24a47a-38dc-4b43-9d78-6b4fc987cab4"
      },
      "source": [
        "bordeaux_train.loc[i_nearest]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>summer</th>\n",
              "      <th>har</th>\n",
              "      <th>sep</th>\n",
              "      <th>win</th>\n",
              "      <th>age</th>\n",
              "      <th>log(price)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>year</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>11.0</td>\n",
              "      <td>16.3</td>\n",
              "      <td>184</td>\n",
              "      <td>16.2</td>\n",
              "      <td>574</td>\n",
              "      <td>18</td>\n",
              "      <td>2.397895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>18.0</td>\n",
              "      <td>16.4</td>\n",
              "      <td>187</td>\n",
              "      <td>19.1</td>\n",
              "      <td>582</td>\n",
              "      <td>34</td>\n",
              "      <td>2.890372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1969</th>\n",
              "      <td>12.0</td>\n",
              "      <td>16.5</td>\n",
              "      <td>244</td>\n",
              "      <td>16.6</td>\n",
              "      <td>575</td>\n",
              "      <td>23</td>\n",
              "      <td>2.484907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>11.0</td>\n",
              "      <td>16.2</td>\n",
              "      <td>292</td>\n",
              "      <td>16.4</td>\n",
              "      <td>610</td>\n",
              "      <td>24</td>\n",
              "      <td>2.397895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980</th>\n",
              "      <td>14.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>74</td>\n",
              "      <td>18.4</td>\n",
              "      <td>578</td>\n",
              "      <td>12</td>\n",
              "      <td>2.639057</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price  summer  har   sep  win  age  log(price)\n",
              "year                                                \n",
              "1974   11.0    16.3  184  16.2  574   18    2.397895\n",
              "1958   18.0    16.4  187  19.1  582   34    2.890372\n",
              "1969   12.0    16.5  244  16.6  575   23    2.484907\n",
              "1968   11.0    16.2  292  16.4  610   24    2.397895\n",
              "1980   14.0    16.0   74  18.4  578   12    2.639057"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CHX2OcrGp3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0bbd48-1572-47b9-f424-4ba857a38052"
      },
      "source": [
        "x_new"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "win       563.0\n",
              "summer     16.3\n",
              "Name: 1986, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzpFu5_GgdqK"
      },
      "source": [
        "To make a prediction for the price of the 1986 vintage, we average the sale prices of these 5-nearest neighbors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfnayFCmgdqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53f6ffd-1219-4607-ff4a-6d4d87997cb7"
      },
      "source": [
        "y_train.loc[i_nearest[:3]].mean()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.591057893494179"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2dNakSEgdqP"
      },
      "source": [
        "So the model predicts that the quality of the 1986 is about 2.56, which is well below the average quality.\n",
        "\n",
        "Of course, the model above only had two features so it was easy to visualize the \"nearest neighbors\" on the scatterplot. The magic of $k$-nearest neighbors is that it still works when there are more features and the data is not possible to visualize."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDVZHOz8gdqQ"
      },
      "source": [
        "## K-Nearest Neighbors in scikit-learn\n",
        "\n",
        "Now let's see how to implement $k$-nearest neighbors in scikit-learn. Recall from the previous lesson that all scikit-learn models follow the three-step pattern:\n",
        "\n",
        "1. Declare the model.\n",
        "2. Fit the model to training data.\n",
        "3. Use the model to predict on test data.\n",
        "\n",
        "To fit a $k$-nearest neighbors model instead of a linear regression model, we only need to modify the first step. Instead of declaring a model of type `LinearRegression`, we define a model of type `KNeighborsRegressor`, specifying the value of $k$ as one of the parameters. Because `KNeighborsRegressor` works with distances, it is a good idea to scale the features before passing the features into the model. (Refer back to Chapter 3 for a full explanation.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z8RozqFgdqQ"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Standardize the training and test data\n",
        "scaler = StandardScaler()\n",
        "X_train_st = scaler.fit_transform(X_train)\n",
        "X_new_st = scaler.transform(pd.DataFrame([x_new])) # needs to be a DataFrame\n",
        "y_train = bordeaux_train[\"log(price)\"]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2B0fadCHnIH",
        "outputId": "cd64253c-8532-4ad8-e73d-842918ddcca4"
      },
      "source": [
        "# Fit k-nearest neighbors\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "model.fit(X=X_train_st, y=y_train)\n",
        "model.predict(X=X_new_st)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.59105789])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TTmEYfeeknc"
      },
      "source": [
        "2.591057893494179"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alv8xS4lIA3C",
        "outputId": "e9b947c6-dd7e-45d9-a7eb-db5cec2c0796"
      },
      "source": [
        "X_train_st.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR7pLTaMH3yg"
      },
      "source": [
        "nei = model.kneighbors_graph()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELO0I0GWIOwu",
        "outputId": "631dba8b-071c-4e98-f229-97058bc88610"
      },
      "source": [
        "nei.toarray()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "        1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
              "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otJtjyw1gdqT"
      },
      "source": [
        "This is the same predicted value that we got by implementing $k$-nearest neighbors manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNrdiBTaggrM"
      },
      "source": [
        "In the code above, we had to be careful to standardize the training data and the test data in exactly the same way before fitting the $k$-nearest neighbors model. Most machine learning models have many more preprocessing steps. As the preprocessing gets more complex, it is easy to accidentally omit one of the preprocessing steps. For this reason, scikit-learn provides a _Pipeline_ object, which simply chains together a sequence of preprocessing and model building steps. If we call `Pipeline.fit()` or `Pipeline.predict()` on the data, all of the steps will be applied to the data in a consistent manner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSFA_1MFggjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8d5718-119c-4c05-837e-ac8c88c9d5fe"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "          StandardScaler(),\n",
        "          KNeighborsRegressor(n_neighbors=5)\n",
        ")\n",
        "\n",
        "pipeline.fit(X=X_train, y=y_train)\n",
        "pipeline.predict(X=pd.DataFrame([x_new]))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.56202526])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAUqRnbagdqU"
      },
      "source": [
        "## The K-Nearest Neighbors Regression Function\n",
        "\n",
        "A predictive model is simply a function $f$ that maps feature values ${\\bf x}$ to target values $y$. We can visualize $f$ when ${\\bf x}$ consists of just a single feature, such as **age**. In the previous lesson, we saw that $f$ is just a line when the model is linear regression. What does $f$ look like when the model is a $k$-nearest neighbors regressor?\n",
        "\n",
        "First, we extract the training data. There is no need to scale the features in this case because there is only one feature. (The point of scaling is to bring all of the variables to the same scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLegUnjjgdqV"
      },
      "source": [
        "X_train = bordeaux_train[[\"age\"]]\n",
        "y_train = bordeaux_train[\"log(price)\"]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seSY9rIhgdqY"
      },
      "source": [
        "Now we fit the $k$-nearest neighbor model as before. We do not need to standardize the feature in this case because there is only one feature. Standardizing is only useful when there are multiple features that we want to bring to the same scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA7yrXhKgdqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27256bbb-c39f-4e4b-a130-7b1738a54ff9"
      },
      "source": [
        "# Fit k-nearest neighbors\n",
        "model = KNeighborsRegressor(n_neighbors=4)\n",
        "model.fit(X=X_train, y=y_train)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                    metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
              "                    weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt8S3Mvpgdqe"
      },
      "source": [
        "In order to graph $f$, we need to evaluate the predictive model at a grid of feature values. Since age ranges from 12 to 40 in the training data, we create a grid of ${\\bf x}$ values from 10 to 45, make predictions at these values, and plot these predictions as a curve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odZD51z6gdqf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "b026f642-4250-4a2f-8617-e43f587274cd"
      },
      "source": [
        "# Define a grid of feature values.\n",
        "X_new = pd.DataFrame()\n",
        "X_new[\"age\"] = np.linspace(10, 45, num=200)\n",
        "\n",
        "# Make predictions at those feature values.\n",
        "y_new_ = pd.Series(\n",
        "    model.predict(X_new),\n",
        "    index=X_new[\"age\"]\n",
        ")\n",
        "\n",
        "# Plot the predictions.\n",
        "bordeaux_train.plot.scatter(x=\"age\", y=\"log(price)\")\n",
        "y_new_.plot.line()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9406af3690>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMkIpaWSgdqi"
      },
      "source": [
        "Unlike the linear regression model, the $k$-nearest neighbor model is piecewise constant. For example, wines more than 37 years old all have the same 5-nearest neighbors, so the prediction is constant in that range."
      ]
    }
  ]
}